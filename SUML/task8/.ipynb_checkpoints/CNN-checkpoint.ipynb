{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science z Python 3.10. Konwersja modeli (fast.ai & TensorFlow)\n",
    "## üá¨üáß Data Science with Python 3.10. Model conversion (fast.ai & TensorFlow)\n",
    "#### üë®‚Äçüè´ PhD Wojciech Oronowicz-Ja≈õkowiak\n",
    "#### ü§ñ https://github.com/aipogodzinach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.\n",
    "### Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy keras tensorflow tf2onnx\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "QWeLG3GHlfhu",
    "outputId": "19c3fbdc-e724-496b-bd76-e9b73d9c08e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('class1', 111), ('class2', 114), ('class3', 136)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = 'dataset_x5'\n",
    "data_dir = 'data_dir'\n",
    "\n",
    "raw_no_of_files = {}\n",
    "classes = ['class1', 'class2', 'class3']\n",
    "for dir in classes:\n",
    "    raw_no_of_files[dir] = len(os.listdir(os.path.join(base_dir, dir)))\n",
    "raw_no_of_files.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ytp_UfCwo08K"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "train_class1_dir = os.path.join(train_dir, '1')\n",
    "train_class2_dir = os.path.join(train_dir, '2')\n",
    "train_class3_dir = os.path.join(train_dir, '3')\n",
    "\n",
    "valid_class1_dir = os.path.join(valid_dir, '1')\n",
    "valid_class2_dir = os.path.join(valid_dir, '2')\n",
    "valid_class3_dir = os.path.join(valid_dir, '3')\n",
    "\n",
    "test_class1_dir = os.path.join(test_dir, '1')\n",
    "test_class2_dir = os.path.join(test_dir, '2')\n",
    "test_class3_dir = os.path.join(test_dir, '3')\n",
    "\n",
    "for directory in (train_dir, valid_dir, test_dir):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "dirs = [train_class1_dir, train_class2_dir, train_class3_dir,\n",
    "        valid_class1_dir, valid_class2_dir, valid_class3_dir,\n",
    "        test_class1_dir, test_class2_dir, test_class3_dir]\n",
    "\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qusrhKHHuOSb"
   },
   "outputs": [],
   "source": [
    "class1_fnames = os.listdir(os.path.join(base_dir, 'class1'))\n",
    "class2_fnames = os.listdir(os.path.join(base_dir, 'class2'))\n",
    "class3_fnames = os.listdir(os.path.join(base_dir, 'class3'))\n",
    "\n",
    "class1_fnames = [fname for fname in class1_fnames if fname.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]\n",
    "class2_fnames = [fname for fname in class2_fnames if fname.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]\n",
    "class3_fnames = [fname for fname in class3_fnames if fname.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DfuC6DFgqh-A"
   },
   "outputs": [],
   "source": [
    "size = min(len(class1_fnames), len(class2_fnames), len(class3_fnames))\n",
    "\n",
    "train_size = int(np.floor(0.7 * size))\n",
    "valid_size = int(np.floor(0.2 * size))\n",
    "test_size = size - train_size - valid_size\n",
    "\n",
    "train_idx = train_size\n",
    "valid_idx = train_size + valid_size\n",
    "test_idx = train_size + valid_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "BHKBORIZsfoa",
    "outputId": "ce3a3ba9-03de-4d8e-b5d9-b4972c1aa7ad"
   },
   "outputs": [],
   "source": [
    "for i, fname in enumerate(class1_fnames):\n",
    "    if i <= train_idx:\n",
    "        src = os.path.join(base_dir, 'class1', fname)\n",
    "        dst = os.path.join(train_class1_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif train_idx < i <= valid_idx:\n",
    "        src = os.path.join(base_dir, 'class1', fname)\n",
    "        dst = os.path.join(valid_class1_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif valid_idx < i < test_idx:\n",
    "        src = os.path.join(base_dir, 'class1', fname)\n",
    "        dst = os.path.join(test_class1_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "for i, fname in enumerate(class2_fnames):\n",
    "    if i <= train_idx:\n",
    "        src = os.path.join(base_dir, 'class2', fname)\n",
    "        dst = os.path.join(train_class2_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif train_idx < i <= valid_idx:\n",
    "        src = os.path.join(base_dir, 'class2', fname)\n",
    "        dst = os.path.join(valid_class2_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif valid_idx < i < test_idx:\n",
    "        src = os.path.join(base_dir, 'class2', fname)\n",
    "        dst = os.path.join(test_class2_dir, fname)\n",
    "        shutil.copyfile(src, dst) \n",
    "\n",
    "for i, fname in enumerate(class3_fnames):\n",
    "    if i <= train_idx:\n",
    "        src = os.path.join(base_dir, 'class3', fname)\n",
    "        dst = os.path.join(train_class3_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif train_idx < i <= valid_idx:\n",
    "        src = os.path.join(base_dir, 'class3', fname)\n",
    "        dst = os.path.join(valid_class3_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif valid_idx < i < test_idx:\n",
    "        src = os.path.join(base_dir, 'class3', fname)\n",
    "        dst = os.path.join(test_class3_dir, fname)\n",
    "        shutil.copyfile(src, dst)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "7mfRlYv35F43",
    "outputId": "5e06f46a-7428-4ffc-dd68-d8568e6c39b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 234 images belonging to 3 classes.\n",
      "Found 66 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                                   target_size=(150, 150),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir,\n",
    "                                                   target_size=(150, 150),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DzLUqI486qFr"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_size // batch_size\n",
    "validation_steps = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "JToulUvDVZCQ",
    "outputId": "0b201043-77db-406d-c647-fe64ae07738f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_name: input_1       trainable: True\n",
      "layer_name: conv1_pad     trainable: True\n",
      "layer_name: conv1_conv    trainable: True\n",
      "layer_name: conv1_bn      trainable: True\n",
      "layer_name: conv1_relu    trainable: True\n",
      "layer_name: pool1_pad     trainable: True\n",
      "layer_name: pool1_pool    trainable: True\n",
      "layer_name: conv2_block1_1_conv trainable: True\n",
      "layer_name: conv2_block1_1_bn trainable: True\n",
      "layer_name: conv2_block1_1_relu trainable: True\n",
      "layer_name: conv2_block1_2_conv trainable: True\n",
      "layer_name: conv2_block1_2_bn trainable: True\n",
      "layer_name: conv2_block1_2_relu trainable: True\n",
      "layer_name: conv2_block1_0_conv trainable: True\n",
      "layer_name: conv2_block1_3_conv trainable: True\n",
      "layer_name: conv2_block1_0_bn trainable: True\n",
      "layer_name: conv2_block1_3_bn trainable: True\n",
      "layer_name: conv2_block1_add trainable: True\n",
      "layer_name: conv2_block1_out trainable: True\n",
      "layer_name: conv2_block2_1_conv trainable: True\n",
      "layer_name: conv2_block2_1_bn trainable: True\n",
      "layer_name: conv2_block2_1_relu trainable: True\n",
      "layer_name: conv2_block2_2_conv trainable: True\n",
      "layer_name: conv2_block2_2_bn trainable: True\n",
      "layer_name: conv2_block2_2_relu trainable: True\n",
      "layer_name: conv2_block2_3_conv trainable: True\n",
      "layer_name: conv2_block2_3_bn trainable: True\n",
      "layer_name: conv2_block2_add trainable: True\n",
      "layer_name: conv2_block2_out trainable: True\n",
      "layer_name: conv2_block3_1_conv trainable: True\n",
      "layer_name: conv2_block3_1_bn trainable: True\n",
      "layer_name: conv2_block3_1_relu trainable: True\n",
      "layer_name: conv2_block3_2_conv trainable: True\n",
      "layer_name: conv2_block3_2_bn trainable: True\n",
      "layer_name: conv2_block3_2_relu trainable: True\n",
      "layer_name: conv2_block3_3_conv trainable: True\n",
      "layer_name: conv2_block3_3_bn trainable: True\n",
      "layer_name: conv2_block3_add trainable: True\n",
      "layer_name: conv2_block3_out trainable: True\n",
      "layer_name: conv3_block1_1_conv trainable: True\n",
      "layer_name: conv3_block1_1_bn trainable: True\n",
      "layer_name: conv3_block1_1_relu trainable: True\n",
      "layer_name: conv3_block1_2_conv trainable: True\n",
      "layer_name: conv3_block1_2_bn trainable: True\n",
      "layer_name: conv3_block1_2_relu trainable: True\n",
      "layer_name: conv3_block1_0_conv trainable: True\n",
      "layer_name: conv3_block1_3_conv trainable: True\n",
      "layer_name: conv3_block1_0_bn trainable: True\n",
      "layer_name: conv3_block1_3_bn trainable: True\n",
      "layer_name: conv3_block1_add trainable: True\n",
      "layer_name: conv3_block1_out trainable: True\n",
      "layer_name: conv3_block2_1_conv trainable: True\n",
      "layer_name: conv3_block2_1_bn trainable: True\n",
      "layer_name: conv3_block2_1_relu trainable: True\n",
      "layer_name: conv3_block2_2_conv trainable: True\n",
      "layer_name: conv3_block2_2_bn trainable: True\n",
      "layer_name: conv3_block2_2_relu trainable: True\n",
      "layer_name: conv3_block2_3_conv trainable: True\n",
      "layer_name: conv3_block2_3_bn trainable: True\n",
      "layer_name: conv3_block2_add trainable: True\n",
      "layer_name: conv3_block2_out trainable: True\n",
      "layer_name: conv3_block3_1_conv trainable: True\n",
      "layer_name: conv3_block3_1_bn trainable: True\n",
      "layer_name: conv3_block3_1_relu trainable: True\n",
      "layer_name: conv3_block3_2_conv trainable: True\n",
      "layer_name: conv3_block3_2_bn trainable: True\n",
      "layer_name: conv3_block3_2_relu trainable: True\n",
      "layer_name: conv3_block3_3_conv trainable: True\n",
      "layer_name: conv3_block3_3_bn trainable: True\n",
      "layer_name: conv3_block3_add trainable: True\n",
      "layer_name: conv3_block3_out trainable: True\n",
      "layer_name: conv3_block4_1_conv trainable: True\n",
      "layer_name: conv3_block4_1_bn trainable: True\n",
      "layer_name: conv3_block4_1_relu trainable: True\n",
      "layer_name: conv3_block4_2_conv trainable: True\n",
      "layer_name: conv3_block4_2_bn trainable: True\n",
      "layer_name: conv3_block4_2_relu trainable: True\n",
      "layer_name: conv3_block4_3_conv trainable: True\n",
      "layer_name: conv3_block4_3_bn trainable: True\n",
      "layer_name: conv3_block4_add trainable: True\n",
      "layer_name: conv3_block4_out trainable: True\n",
      "layer_name: conv4_block1_1_conv trainable: True\n",
      "layer_name: conv4_block1_1_bn trainable: True\n",
      "layer_name: conv4_block1_1_relu trainable: True\n",
      "layer_name: conv4_block1_2_conv trainable: True\n",
      "layer_name: conv4_block1_2_bn trainable: True\n",
      "layer_name: conv4_block1_2_relu trainable: True\n",
      "layer_name: conv4_block1_0_conv trainable: True\n",
      "layer_name: conv4_block1_3_conv trainable: True\n",
      "layer_name: conv4_block1_0_bn trainable: True\n",
      "layer_name: conv4_block1_3_bn trainable: True\n",
      "layer_name: conv4_block1_add trainable: True\n",
      "layer_name: conv4_block1_out trainable: True\n",
      "layer_name: conv4_block2_1_conv trainable: True\n",
      "layer_name: conv4_block2_1_bn trainable: True\n",
      "layer_name: conv4_block2_1_relu trainable: True\n",
      "layer_name: conv4_block2_2_conv trainable: True\n",
      "layer_name: conv4_block2_2_bn trainable: True\n",
      "layer_name: conv4_block2_2_relu trainable: True\n",
      "layer_name: conv4_block2_3_conv trainable: True\n",
      "layer_name: conv4_block2_3_bn trainable: True\n",
      "layer_name: conv4_block2_add trainable: True\n",
      "layer_name: conv4_block2_out trainable: True\n",
      "layer_name: conv4_block3_1_conv trainable: True\n",
      "layer_name: conv4_block3_1_bn trainable: True\n",
      "layer_name: conv4_block3_1_relu trainable: True\n",
      "layer_name: conv4_block3_2_conv trainable: True\n",
      "layer_name: conv4_block3_2_bn trainable: True\n",
      "layer_name: conv4_block3_2_relu trainable: True\n",
      "layer_name: conv4_block3_3_conv trainable: True\n",
      "layer_name: conv4_block3_3_bn trainable: True\n",
      "layer_name: conv4_block3_add trainable: True\n",
      "layer_name: conv4_block3_out trainable: True\n",
      "layer_name: conv4_block4_1_conv trainable: True\n",
      "layer_name: conv4_block4_1_bn trainable: True\n",
      "layer_name: conv4_block4_1_relu trainable: True\n",
      "layer_name: conv4_block4_2_conv trainable: True\n",
      "layer_name: conv4_block4_2_bn trainable: True\n",
      "layer_name: conv4_block4_2_relu trainable: True\n",
      "layer_name: conv4_block4_3_conv trainable: True\n",
      "layer_name: conv4_block4_3_bn trainable: True\n",
      "layer_name: conv4_block4_add trainable: True\n",
      "layer_name: conv4_block4_out trainable: True\n",
      "layer_name: conv4_block5_1_conv trainable: True\n",
      "layer_name: conv4_block5_1_bn trainable: True\n",
      "layer_name: conv4_block5_1_relu trainable: True\n",
      "layer_name: conv4_block5_2_conv trainable: True\n",
      "layer_name: conv4_block5_2_bn trainable: True\n",
      "layer_name: conv4_block5_2_relu trainable: True\n",
      "layer_name: conv4_block5_3_conv trainable: True\n",
      "layer_name: conv4_block5_3_bn trainable: True\n",
      "layer_name: conv4_block5_add trainable: True\n",
      "layer_name: conv4_block5_out trainable: True\n",
      "layer_name: conv4_block6_1_conv trainable: True\n",
      "layer_name: conv4_block6_1_bn trainable: True\n",
      "layer_name: conv4_block6_1_relu trainable: True\n",
      "layer_name: conv4_block6_2_conv trainable: True\n",
      "layer_name: conv4_block6_2_bn trainable: True\n",
      "layer_name: conv4_block6_2_relu trainable: True\n",
      "layer_name: conv4_block6_3_conv trainable: True\n",
      "layer_name: conv4_block6_3_bn trainable: True\n",
      "layer_name: conv4_block6_add trainable: True\n",
      "layer_name: conv4_block6_out trainable: True\n",
      "layer_name: conv5_block1_1_conv trainable: True\n",
      "layer_name: conv5_block1_1_bn trainable: True\n",
      "layer_name: conv5_block1_1_relu trainable: True\n",
      "layer_name: conv5_block1_2_conv trainable: True\n",
      "layer_name: conv5_block1_2_bn trainable: True\n",
      "layer_name: conv5_block1_2_relu trainable: True\n",
      "layer_name: conv5_block1_0_conv trainable: True\n",
      "layer_name: conv5_block1_3_conv trainable: True\n",
      "layer_name: conv5_block1_0_bn trainable: True\n",
      "layer_name: conv5_block1_3_bn trainable: True\n",
      "layer_name: conv5_block1_add trainable: True\n",
      "layer_name: conv5_block1_out trainable: True\n",
      "layer_name: conv5_block2_1_conv trainable: True\n",
      "layer_name: conv5_block2_1_bn trainable: True\n",
      "layer_name: conv5_block2_1_relu trainable: True\n",
      "layer_name: conv5_block2_2_conv trainable: True\n",
      "layer_name: conv5_block2_2_bn trainable: True\n",
      "layer_name: conv5_block2_2_relu trainable: True\n",
      "layer_name: conv5_block2_3_conv trainable: True\n",
      "layer_name: conv5_block2_3_bn trainable: True\n",
      "layer_name: conv5_block2_add trainable: True\n",
      "layer_name: conv5_block2_out trainable: True\n",
      "layer_name: conv5_block3_1_conv trainable: True\n",
      "layer_name: conv5_block3_1_bn trainable: True\n",
      "layer_name: conv5_block3_1_relu trainable: True\n",
      "layer_name: conv5_block3_2_conv trainable: True\n",
      "layer_name: conv5_block3_2_bn trainable: True\n",
      "layer_name: conv5_block3_2_relu trainable: True\n",
      "layer_name: conv5_block3_3_conv trainable: True\n",
      "layer_name: conv5_block3_3_bn trainable: True\n",
      "layer_name: conv5_block3_add trainable: True\n",
      "layer_name: conv5_block3_out trainable: True\n"
     ]
    }
   ],
   "source": [
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "conv_base.trainable = True\n",
    "\n",
    "def print_layers(model):\n",
    "    for layer in model.layers:\n",
    "        print(f'layer_name: {layer.name:13} trainable: {layer.trainable}')\n",
    "\n",
    "print_layers(conv_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "GUtDUJzxWL8r",
    "outputId": "e74be590-b7ae-4f3d-a12c-0cce425dcb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_name: input_1       trainable: False\n",
      "layer_name: conv1_pad     trainable: False\n",
      "layer_name: conv1_conv    trainable: False\n",
      "layer_name: conv1_bn      trainable: False\n",
      "layer_name: conv1_relu    trainable: False\n",
      "layer_name: pool1_pad     trainable: False\n",
      "layer_name: pool1_pool    trainable: False\n",
      "layer_name: conv2_block1_1_conv trainable: False\n",
      "layer_name: conv2_block1_1_bn trainable: False\n",
      "layer_name: conv2_block1_1_relu trainable: False\n",
      "layer_name: conv2_block1_2_conv trainable: False\n",
      "layer_name: conv2_block1_2_bn trainable: False\n",
      "layer_name: conv2_block1_2_relu trainable: False\n",
      "layer_name: conv2_block1_0_conv trainable: False\n",
      "layer_name: conv2_block1_3_conv trainable: False\n",
      "layer_name: conv2_block1_0_bn trainable: False\n",
      "layer_name: conv2_block1_3_bn trainable: False\n",
      "layer_name: conv2_block1_add trainable: False\n",
      "layer_name: conv2_block1_out trainable: False\n",
      "layer_name: conv2_block2_1_conv trainable: False\n",
      "layer_name: conv2_block2_1_bn trainable: False\n",
      "layer_name: conv2_block2_1_relu trainable: False\n",
      "layer_name: conv2_block2_2_conv trainable: False\n",
      "layer_name: conv2_block2_2_bn trainable: False\n",
      "layer_name: conv2_block2_2_relu trainable: False\n",
      "layer_name: conv2_block2_3_conv trainable: False\n",
      "layer_name: conv2_block2_3_bn trainable: False\n",
      "layer_name: conv2_block2_add trainable: False\n",
      "layer_name: conv2_block2_out trainable: False\n",
      "layer_name: conv2_block3_1_conv trainable: False\n",
      "layer_name: conv2_block3_1_bn trainable: False\n",
      "layer_name: conv2_block3_1_relu trainable: False\n",
      "layer_name: conv2_block3_2_conv trainable: False\n",
      "layer_name: conv2_block3_2_bn trainable: False\n",
      "layer_name: conv2_block3_2_relu trainable: False\n",
      "layer_name: conv2_block3_3_conv trainable: False\n",
      "layer_name: conv2_block3_3_bn trainable: False\n",
      "layer_name: conv2_block3_add trainable: False\n",
      "layer_name: conv2_block3_out trainable: False\n",
      "layer_name: conv3_block1_1_conv trainable: False\n",
      "layer_name: conv3_block1_1_bn trainable: False\n",
      "layer_name: conv3_block1_1_relu trainable: False\n",
      "layer_name: conv3_block1_2_conv trainable: False\n",
      "layer_name: conv3_block1_2_bn trainable: False\n",
      "layer_name: conv3_block1_2_relu trainable: False\n",
      "layer_name: conv3_block1_0_conv trainable: False\n",
      "layer_name: conv3_block1_3_conv trainable: False\n",
      "layer_name: conv3_block1_0_bn trainable: False\n",
      "layer_name: conv3_block1_3_bn trainable: False\n",
      "layer_name: conv3_block1_add trainable: False\n",
      "layer_name: conv3_block1_out trainable: False\n",
      "layer_name: conv3_block2_1_conv trainable: False\n",
      "layer_name: conv3_block2_1_bn trainable: False\n",
      "layer_name: conv3_block2_1_relu trainable: False\n",
      "layer_name: conv3_block2_2_conv trainable: False\n",
      "layer_name: conv3_block2_2_bn trainable: False\n",
      "layer_name: conv3_block2_2_relu trainable: False\n",
      "layer_name: conv3_block2_3_conv trainable: False\n",
      "layer_name: conv3_block2_3_bn trainable: False\n",
      "layer_name: conv3_block2_add trainable: False\n",
      "layer_name: conv3_block2_out trainable: False\n",
      "layer_name: conv3_block3_1_conv trainable: False\n",
      "layer_name: conv3_block3_1_bn trainable: False\n",
      "layer_name: conv3_block3_1_relu trainable: False\n",
      "layer_name: conv3_block3_2_conv trainable: False\n",
      "layer_name: conv3_block3_2_bn trainable: False\n",
      "layer_name: conv3_block3_2_relu trainable: False\n",
      "layer_name: conv3_block3_3_conv trainable: False\n",
      "layer_name: conv3_block3_3_bn trainable: False\n",
      "layer_name: conv3_block3_add trainable: False\n",
      "layer_name: conv3_block3_out trainable: False\n",
      "layer_name: conv3_block4_1_conv trainable: False\n",
      "layer_name: conv3_block4_1_bn trainable: False\n",
      "layer_name: conv3_block4_1_relu trainable: False\n",
      "layer_name: conv3_block4_2_conv trainable: False\n",
      "layer_name: conv3_block4_2_bn trainable: False\n",
      "layer_name: conv3_block4_2_relu trainable: False\n",
      "layer_name: conv3_block4_3_conv trainable: False\n",
      "layer_name: conv3_block4_3_bn trainable: False\n",
      "layer_name: conv3_block4_add trainable: False\n",
      "layer_name: conv3_block4_out trainable: False\n",
      "layer_name: conv4_block1_1_conv trainable: False\n",
      "layer_name: conv4_block1_1_bn trainable: False\n",
      "layer_name: conv4_block1_1_relu trainable: False\n",
      "layer_name: conv4_block1_2_conv trainable: False\n",
      "layer_name: conv4_block1_2_bn trainable: False\n",
      "layer_name: conv4_block1_2_relu trainable: False\n",
      "layer_name: conv4_block1_0_conv trainable: False\n",
      "layer_name: conv4_block1_3_conv trainable: False\n",
      "layer_name: conv4_block1_0_bn trainable: False\n",
      "layer_name: conv4_block1_3_bn trainable: False\n",
      "layer_name: conv4_block1_add trainable: False\n",
      "layer_name: conv4_block1_out trainable: False\n",
      "layer_name: conv4_block2_1_conv trainable: False\n",
      "layer_name: conv4_block2_1_bn trainable: False\n",
      "layer_name: conv4_block2_1_relu trainable: False\n",
      "layer_name: conv4_block2_2_conv trainable: False\n",
      "layer_name: conv4_block2_2_bn trainable: False\n",
      "layer_name: conv4_block2_2_relu trainable: False\n",
      "layer_name: conv4_block2_3_conv trainable: False\n",
      "layer_name: conv4_block2_3_bn trainable: False\n",
      "layer_name: conv4_block2_add trainable: False\n",
      "layer_name: conv4_block2_out trainable: False\n",
      "layer_name: conv4_block3_1_conv trainable: False\n",
      "layer_name: conv4_block3_1_bn trainable: False\n",
      "layer_name: conv4_block3_1_relu trainable: False\n",
      "layer_name: conv4_block3_2_conv trainable: False\n",
      "layer_name: conv4_block3_2_bn trainable: False\n",
      "layer_name: conv4_block3_2_relu trainable: False\n",
      "layer_name: conv4_block3_3_conv trainable: False\n",
      "layer_name: conv4_block3_3_bn trainable: False\n",
      "layer_name: conv4_block3_add trainable: False\n",
      "layer_name: conv4_block3_out trainable: False\n",
      "layer_name: conv4_block4_1_conv trainable: False\n",
      "layer_name: conv4_block4_1_bn trainable: False\n",
      "layer_name: conv4_block4_1_relu trainable: False\n",
      "layer_name: conv4_block4_2_conv trainable: False\n",
      "layer_name: conv4_block4_2_bn trainable: False\n",
      "layer_name: conv4_block4_2_relu trainable: False\n",
      "layer_name: conv4_block4_3_conv trainable: False\n",
      "layer_name: conv4_block4_3_bn trainable: False\n",
      "layer_name: conv4_block4_add trainable: False\n",
      "layer_name: conv4_block4_out trainable: False\n",
      "layer_name: conv4_block5_1_conv trainable: False\n",
      "layer_name: conv4_block5_1_bn trainable: False\n",
      "layer_name: conv4_block5_1_relu trainable: False\n",
      "layer_name: conv4_block5_2_conv trainable: False\n",
      "layer_name: conv4_block5_2_bn trainable: False\n",
      "layer_name: conv4_block5_2_relu trainable: False\n",
      "layer_name: conv4_block5_3_conv trainable: False\n",
      "layer_name: conv4_block5_3_bn trainable: False\n",
      "layer_name: conv4_block5_add trainable: False\n",
      "layer_name: conv4_block5_out trainable: False\n",
      "layer_name: conv4_block6_1_conv trainable: False\n",
      "layer_name: conv4_block6_1_bn trainable: False\n",
      "layer_name: conv4_block6_1_relu trainable: False\n",
      "layer_name: conv4_block6_2_conv trainable: False\n",
      "layer_name: conv4_block6_2_bn trainable: False\n",
      "layer_name: conv4_block6_2_relu trainable: False\n",
      "layer_name: conv4_block6_3_conv trainable: False\n",
      "layer_name: conv4_block6_3_bn trainable: False\n",
      "layer_name: conv4_block6_add trainable: False\n",
      "layer_name: conv4_block6_out trainable: False\n",
      "layer_name: conv5_block1_1_conv trainable: False\n",
      "layer_name: conv5_block1_1_bn trainable: False\n",
      "layer_name: conv5_block1_1_relu trainable: False\n",
      "layer_name: conv5_block1_2_conv trainable: False\n",
      "layer_name: conv5_block1_2_bn trainable: False\n",
      "layer_name: conv5_block1_2_relu trainable: False\n",
      "layer_name: conv5_block1_0_conv trainable: False\n",
      "layer_name: conv5_block1_3_conv trainable: False\n",
      "layer_name: conv5_block1_0_bn trainable: False\n",
      "layer_name: conv5_block1_3_bn trainable: False\n",
      "layer_name: conv5_block1_add trainable: False\n",
      "layer_name: conv5_block1_out trainable: False\n",
      "layer_name: conv5_block2_1_conv trainable: False\n",
      "layer_name: conv5_block2_1_bn trainable: False\n",
      "layer_name: conv5_block2_1_relu trainable: False\n",
      "layer_name: conv5_block2_2_conv trainable: False\n",
      "layer_name: conv5_block2_2_bn trainable: False\n",
      "layer_name: conv5_block2_2_relu trainable: False\n",
      "layer_name: conv5_block2_3_conv trainable: False\n",
      "layer_name: conv5_block2_3_bn trainable: False\n",
      "layer_name: conv5_block2_add trainable: False\n",
      "layer_name: conv5_block2_out trainable: False\n",
      "layer_name: conv5_block3_1_conv trainable: False\n",
      "layer_name: conv5_block3_1_bn trainable: False\n",
      "layer_name: conv5_block3_1_relu trainable: False\n",
      "layer_name: conv5_block3_2_conv trainable: False\n",
      "layer_name: conv5_block3_2_bn trainable: False\n",
      "layer_name: conv5_block3_2_relu trainable: False\n",
      "layer_name: conv5_block3_3_conv trainable: False\n",
      "layer_name: conv5_block3_3_bn trainable: False\n",
      "layer_name: conv5_block3_add trainable: False\n",
      "layer_name: conv5_block3_out trainable: False\n"
     ]
    }
   ],
   "source": [
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "print_layers(conv_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "IGUM0ABqWo3a",
    "outputId": "8f1a8ee3-909d-43ba-cf8f-52df20b374f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               13107456  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,695,939\n",
      "Trainable params: 13,108,227\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamjedrzejewski/code/PJATK/SUML/task8/env_3.10/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=256, activation='relu'))\n",
    "model.add(layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 14:53:07.351689: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 437ms/step - loss: 2.3404 - accuracy: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x296d19090>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=1, steps_per_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JbFmJSS6_X--"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               13107456  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,695,939\n",
      "Trainable params: 13,108,227\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.load_model('saved_model/my_model2')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\",\n",
       " '  warn(RuntimeWarning(msg))',\n",
       " '2022-12-04 14:54:29,238 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557',\n",
       " \"2022-12-04 14:54:29,238 - WARNING - '--tag' not specified for saved_model. Using --tag serve\",\n",
       " '2022-12-04 14:54:38,157 - INFO - Signatures found in model: [serving_default].',\n",
       " \"2022-12-04 14:54:38,157 - WARNING - '--signature_def' not specified, using first signature: serving_default\",\n",
       " \"2022-12-04 14:54:38,158 - INFO - Output names: ['dense_1']\",\n",
       " '2022-12-04 14:54:41,071 - INFO - Using tensorflow=2.10.0, onnx=1.12.0, tf2onnx=1.13.0/2c1db5',\n",
       " '2022-12-04 14:54:41,071 - INFO - Using opset <onnx, 13>',\n",
       " '2022-12-04 14:54:41,342 - INFO - Computed 0 values for constant folding',\n",
       " '2022-12-04 14:54:41,867 - INFO - Optimizing ONNX model',\n",
       " '2022-12-04 14:54:43,441 - INFO - After optimization: Add -1 (19->18), BatchNormalization -53 (53->0), Cast -1 (1->0), Const -161 (273->112), Identity -2 (2->0), Transpose -212 (214->2)',\n",
       " '2022-12-04 14:54:43,496 - INFO - ',\n",
       " '2022-12-04 14:54:43,496 - INFO - Successfully converted TensorFlow model saved_model/my_model2 to ONNX',\n",
       " \"2022-12-04 14:54:43,496 - INFO - Model inputs: ['resnet50_input']\",\n",
       " \"2022-12-04 14:54:43,496 - INFO - Model outputs: ['dense_1']\",\n",
       " '2022-12-04 14:54:43,496 - INFO - ONNX model is saved at tfmodel.onnx']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacky solution\n",
    "# for some reason I had to upgrade protobuf to 4.21.10\n",
    "# copy internal/builder.py to temporary storage\n",
    "# downgrade protobuf to 3.19.4\n",
    "# copy builder.py from temporary storage to internal/builder.py\n",
    "# protobuf is garbage\n",
    "!!python -m tf2onnx.convert --saved-model saved_model/my_model2 --output tfmodel.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2.\n",
    "### Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamjedrzejewski/code/PJATK/SUML/task8/env_3.10/lib/python3.10/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
      "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
      "/Users/adamjedrzejewski/code/PJATK/SUML/task8/env_3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/adamjedrzejewski/code/PJATK/SUML/task8/env_3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/adamjedrzejewski/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06793fdea264f5793140026cbc9f715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.839371</td>\n",
       "      <td>0.058481</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install fastai==2.5.3 fastbook==0.0.18 torch==1.10.0 torchvision==0.11.1 seeme\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "\n",
    "import pathlib\n",
    "import fastai\n",
    "from pathlib import Path\n",
    "\n",
    "temp = pathlib.PosixPath\n",
    "# pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "path = Path('dataset_x5')\n",
    "\n",
    "classes = 'class1', 'class2', 'class3'\n",
    "\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2,seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128)\n",
    ")\n",
    "\n",
    "data = data.new(\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms(mult=0.0, do_flip=False, flip_vert=False, max_rotate=0.0, min_zoom=0.0, max_zoom=0.0, max_lighting=0.0, max_warp=0.0, p_affine=0.0, p_lighting=0.0, xtra_tfms=None, size=None, mode='bilinear', pad_mode='border', align_corners=True, batch=False, min_scale=1.0))\n",
    "\n",
    "dls = data.dataloaders(path, bs = 32)\n",
    "\n",
    "learn = cnn_learner(dls, resnet18, metrics=error_rate)\n",
    "\n",
    "learn.fit_one_cycle(1)\n",
    "learn.export(fname=\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "\n",
    "model_file = open(\"model.pkl\", 'rb')\n",
    "model = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "\n",
    "model_eval = model.eval()\n",
    "dummy_image = torch.randn(1, 3, 64, 64)\n",
    "torch.onnx.export(model_eval, dummy_image, \"model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
